{
 "cells": [],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "{\n",
     " \"cells\": [\n",
     "  {\n",
     "   \"cell_type\": \"markdown\",\n",
     "   \"metadata\": {},\n",
     "   \"source\": [\n",
     "    \"# Keras\\n\",\n",
     "    \"\\n\",\n",
     "    \"Keras 是一个用于构建和训练深度学习模型的高阶 API。它可用于快速设计原型、高级研究和生产。\\n\",\n",
     "    \"\\n\",\n",
     "    \"keras的3个优点：\\n\",\n",
     "    \"方便用户使用、模块化和可组合、易于扩展\\n\",\n",
     "    \"\\n\",\n",
     "    \"\\n\",\n",
     "    \"##  1.导入tf.keras\\n\",\n",
     "    \"tensorflow2推荐使用keras构建网络，常见的神经网络都包含在keras.layer中(最新的tf.keras的版本可能和keras不同)\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"code\",\n",
     "   \"execution_count\": 1,\n",
     "   \"metadata\": {},\n",
     "   \"outputs\": [\n",
     "    {\n",
     "     \"name\": \"stdout\",\n",
     "     \"output_type\": \"stream\",\n",
     "     \"text\": [\n",
     "      \"2.0.0-alpha0\\n\",\n",
     "      \"2.2.4-tf\\n\"\n",
     "     ]\n",
     "    }\n",
     "   ],\n",
     "   \"source\": [\n",
     "    \"import tensorflow as tf\\n\",\n",
     "    \"from tensorflow.keras import layers\\n\",\n",
     "    \"print(tf.__version__)\\n\",\n",
     "    \"print(tf.keras.__version__)\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"markdown\",\n",
     "   \"metadata\": {},\n",
     "   \"source\": [\n",
     "    \"## 2.构建简单模型\\n\",\n",
     "    \"### 2.1模型堆叠\\n\",\n",
     "    \"最常见的模型类型是层的堆叠：tf.keras.Sequential 模型\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"code\",\n",
     "   \"execution_count\": 2,\n",
     "   \"metadata\": {},\n",
     "   \"outputs\": [],\n",
     "   \"source\": [\n",
     "    \"model = tf.keras.Sequential()\\n\",\n",
     "    \"model.add(layers.Dense(32, activation='relu'))\\n\",\n",
     "    \"model.add(layers.Dense(32, activation='relu'))\\n\",\n",
     "    \"model.add(layers.Dense(10, activation='softmax'))\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"markdown\",\n",
     "   \"metadata\": {},\n",
     "   \"source\": [\n",
     "    \"### 2.2网络配置\\n\",\n",
     "    \"\\n\",\n",
     "    \"tf.keras.layers中网络配置：\\n\",\n",
     "    \"\\n\",\n",
     "    \"activation：设置层的激活函数。此参数由内置函数的名称指定，或指定为可调用对象。默认情况下，系统不会应用任何激活函数。\\n\",\n",
     "    \"\\n\",\n",
     "    \"kernel_initializer 和 bias_initializer：创建层权重（核和偏差）的初始化方案。此参数是一个名称或可调用对象，默认为 \\\"Glorot uniform\\\" 初始化器。\\n\",\n",
     "    \"\\n\",\n",
     "    \"kernel_regularizer 和 bias_regularizer：应用层权重（核和偏差）的正则化方案，例如 L1 或 L2 正则化。默认情况下，系统不会应用正则化函数。\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"code\",\n",
     "   \"execution_count\": 3,\n",
     "   \"metadata\": {},\n",
     "   \"outputs\": [\n",
     "    {\n",
     "     \"data\": {\n",
     "      \"text/plain\": [\n",
     "       \"<tensorflow.python.keras.layers.core.Dense at 0x7f99c444ddd8>\"\n",
     "      ]\n",
     "     },\n",
     "     \"execution_count\": 3,\n",
     "     \"metadata\": {},\n",
     "     \"output_type\": \"execute_result\"\n",
     "    }\n",
     "   ],\n",
     "   \"source\": [\n",
     "    \"layers.Dense(32, activation='sigmoid')\\n\",\n",
     "    \"layers.Dense(32, activation=tf.sigmoid)\\n\",\n",
     "    \"layers.Dense(32, kernel_initializer='orthogonal')\\n\",\n",
     "    \"layers.Dense(32, kernel_initializer=tf.keras.initializers.glorot_normal)\\n\",\n",
     "    \"layers.Dense(32, kernel_regularizer=tf.keras.regularizers.l2(0.01))\\n\",\n",
     "    \"layers.Dense(32, kernel_regularizer=tf.keras.regularizers.l1(0.01))\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"markdown\",\n",
     "   \"metadata\": {},\n",
     "   \"source\": [\n",
     "    \"## 3.训练和评估\\n\",\n",
     "    \"### 3.1设置训练流程\\n\",\n",
     "    \"构建好模型后，通过调用 compile 方法配置该模型的学习流程：\\n\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"code\",\n",
     "   \"execution_count\": 4,\n",
     "   \"metadata\": {},\n",
     "   \"outputs\": [],\n",
     "   \"source\": [\n",
     "    \"model = tf.keras.Sequential()\\n\",\n",
     "    \"model.add(layers.Dense(32, activation='relu'))\\n\",\n",
     "    \"model.add(layers.Dense(32, activation='relu'))\\n\",\n",
     "    \"model.add(layers.Dense(10, activation='softmax'))\\n\",\n",
     "    \"model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\\n\",\n",
     "    \"             loss=tf.keras.losses.categorical_crossentropy,\\n\",\n",
     "    \"             metrics=[tf.keras.metrics.categorical_accuracy])\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"markdown\",\n",
     "   \"metadata\": {},\n",
     "   \"source\": [\n",
     "    \"### 3.2输入Numpy数据\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"code\",\n",
     "   \"execution_count\": 5,\n",
     "   \"metadata\": {\n",
     "    \"scrolled\": true\n",
     "   },\n",
     "   \"outputs\": [\n",
     "    {\n",
     "     \"name\": \"stdout\",\n",
     "     \"output_type\": \"stream\",\n",
     "     \"text\": [\n",
     "      \"Train on 1000 samples, validate on 200 samples\\n\",\n",
     "      \"Epoch 1/10\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 302us/sample - loss: 11.8430 - categorical_accuracy: 0.0940 - val_loss: 11.8829 - val_categorical_accuracy: 0.0850\\n\",\n",
     "      \"Epoch 2/10\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 13us/sample - loss: 12.2077 - categorical_accuracy: 0.0850 - val_loss: 12.6407 - val_categorical_accuracy: 0.0850\\n\",\n",
     "      \"Epoch 3/10\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 25us/sample - loss: 13.3500 - categorical_accuracy: 0.0940 - val_loss: 14.4725 - val_categorical_accuracy: 0.0850\\n\",\n",
     "      \"Epoch 4/10\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 22us/sample - loss: 15.7563 - categorical_accuracy: 0.1070 - val_loss: 17.8371 - val_categorical_accuracy: 0.0850\\n\",\n",
     "      \"Epoch 5/10\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 22us/sample - loss: 19.9573 - categorical_accuracy: 0.1000 - val_loss: 23.3407 - val_categorical_accuracy: 0.0750\\n\",\n",
     "      \"Epoch 6/10\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 29us/sample - loss: 25.7599 - categorical_accuracy: 0.1010 - val_loss: 29.8918 - val_categorical_accuracy: 0.0750\\n\",\n",
     "      \"Epoch 7/10\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 25us/sample - loss: 33.3439 - categorical_accuracy: 0.1030 - val_loss: 39.8591 - val_categorical_accuracy: 0.0650\\n\",\n",
     "      \"Epoch 8/10\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 30us/sample - loss: 44.7319 - categorical_accuracy: 0.1010 - val_loss: 53.5336 - val_categorical_accuracy: 0.0550\\n\",\n",
     "      \"Epoch 9/10\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 22us/sample - loss: 58.9997 - categorical_accuracy: 0.1050 - val_loss: 69.6580 - val_categorical_accuracy: 0.0500\\n\",\n",
     "      \"Epoch 10/10\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 32us/sample - loss: 76.0207 - categorical_accuracy: 0.1040 - val_loss: 89.1147 - val_categorical_accuracy: 0.0700\\n\"\n",
     "     ]\n",
     "    },\n",
     "    {\n",
     "     \"data\": {\n",
     "      \"text/plain\": [\n",
     "       \"<tensorflow.python.keras.callbacks.History at 0x7f99c0370390>\"\n",
     "      ]\n",
     "     },\n",
     "     \"execution_count\": 5,\n",
     "     \"metadata\": {},\n",
     "     \"output_type\": \"execute_result\"\n",
     "    }\n",
     "   ],\n",
     "   \"source\": [\n",
     "    \"import numpy as np\\n\",\n",
     "    \"\\n\",\n",
     "    \"train_x = np.random.random((1000, 72))\\n\",\n",
     "    \"train_y = np.random.random((1000, 10))\\n\",\n",
     "    \"\\n\",\n",
     "    \"val_x = np.random.random((200, 72))\\n\",\n",
     "    \"val_y = np.random.random((200, 10))\\n\",\n",
     "    \"\\n\",\n",
     "    \"model.fit(train_x, train_y, epochs=10, batch_size=100,\\n\",\n",
     "    \"          validation_data=(val_x, val_y))\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"markdown\",\n",
     "   \"metadata\": {},\n",
     "   \"source\": [\n",
     "    \"### 3.3tf.data输入数据\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"code\",\n",
     "   \"execution_count\": 6,\n",
     "   \"metadata\": {},\n",
     "   \"outputs\": [\n",
     "    {\n",
     "     \"name\": \"stderr\",\n",
     "     \"output_type\": \"stream\",\n",
     "     \"text\": [\n",
     "      \"WARNING: Logging before flag parsing goes to stderr.\\n\",\n",
     "      \"W0308 22:45:22.538554 140299441469184 training_utils.py:1353] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\\n\"\n",
     "     ]\n",
     "    },\n",
     "    {\n",
     "     \"name\": \"stdout\",\n",
     "     \"output_type\": \"stream\",\n",
     "     \"text\": [\n",
     "      \"Epoch 1/10\\n\",\n",
     "      \"30/30 [==============================] - 0s 4ms/step - loss: 120.5764 - categorical_accuracy: 0.1094 - val_loss: 167.2411 - val_categorical_accuracy: 0.0833\\n\",\n",
     "      \"Epoch 2/10\\n\",\n",
     "      \"30/30 [==============================] - 0s 3ms/step - loss: 208.8775 - categorical_accuracy: 0.0983 - val_loss: 272.6065 - val_categorical_accuracy: 0.1250\\n\",\n",
     "      \"Epoch 3/10\\n\",\n",
     "      \"30/30 [==============================] - 0s 3ms/step - loss: 323.3857 - categorical_accuracy: 0.0962 - val_loss: 401.4161 - val_categorical_accuracy: 0.0833\\n\",\n",
     "      \"Epoch 4/10\\n\",\n",
     "      \"30/30 [==============================] - 0s 3ms/step - loss: 457.8510 - categorical_accuracy: 0.1015 - val_loss: 546.6275 - val_categorical_accuracy: 0.0833\\n\",\n",
     "      \"Epoch 5/10\\n\",\n",
     "      \"30/30 [==============================] - 0s 2ms/step - loss: 609.1648 - categorical_accuracy: 0.1197 - val_loss: 712.8060 - val_categorical_accuracy: 0.0938\\n\",\n",
     "      \"Epoch 6/10\\n\",\n",
     "      \"30/30 [==============================] - 0s 2ms/step - loss: 780.5939 - categorical_accuracy: 0.0972 - val_loss: 891.2927 - val_categorical_accuracy: 0.0938\\n\",\n",
     "      \"Epoch 7/10\\n\",\n",
     "      \"30/30 [==============================] - 0s 3ms/step - loss: 956.0356 - categorical_accuracy: 0.0962 - val_loss: 1068.0684 - val_categorical_accuracy: 0.1354\\n\",\n",
     "      \"Epoch 8/10\\n\",\n",
     "      \"30/30 [==============================] - 0s 3ms/step - loss: 1116.4347 - categorical_accuracy: 0.0940 - val_loss: 1220.6263 - val_categorical_accuracy: 0.1042\\n\",\n",
     "      \"Epoch 9/10\\n\",\n",
     "      \"30/30 [==============================] - 0s 2ms/step - loss: 1252.2060 - categorical_accuracy: 0.0833 - val_loss: 1364.1936 - val_categorical_accuracy: 0.0833\\n\",\n",
     "      \"Epoch 10/10\\n\",\n",
     "      \"30/30 [==============================] - 0s 2ms/step - loss: 1392.8480 - categorical_accuracy: 0.0897 - val_loss: 1507.7679 - val_categorical_accuracy: 0.0938\\n\"\n",
     "     ]\n",
     "    },\n",
     "    {\n",
     "     \"data\": {\n",
     "      \"text/plain\": [\n",
     "       \"<tensorflow.python.keras.callbacks.History at 0x7f99c47661d0>\"\n",
     "      ]\n",
     "     },\n",
     "     \"execution_count\": 6,\n",
     "     \"metadata\": {},\n",
     "     \"output_type\": \"execute_result\"\n",
     "    }\n",
     "   ],\n",
     "   \"source\": [\n",
     "    \"dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\\n\",\n",
     "    \"dataset = dataset.batch(32)\\n\",\n",
     "    \"dataset = dataset.repeat()\\n\",\n",
     "    \"val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))\\n\",\n",
     "    \"val_dataset = val_dataset.batch(32)\\n\",\n",
     "    \"val_dataset = val_dataset.repeat()\\n\",\n",
     "    \"\\n\",\n",
     "    \"model.fit(dataset, epochs=10, steps_per_epoch=30,\\n\",\n",
     "    \"          validation_data=val_dataset, validation_steps=3)\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"markdown\",\n",
     "   \"metadata\": {},\n",
     "   \"source\": [\n",
     "    \"### 3.4评估与预测\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"code\",\n",
     "   \"execution_count\": 7,\n",
     "   \"metadata\": {},\n",
     "   \"outputs\": [\n",
     "    {\n",
     "     \"name\": \"stdout\",\n",
     "     \"output_type\": \"stream\",\n",
     "     \"text\": [\n",
     "      \"1000/1000 [==============================] - 0s 37us/sample - loss: 1436.8957 - categorical_accuracy: 0.0930\\n\",\n",
     "      \"30/30 [==============================] - 0s 2ms/step - loss: 1434.2727 - categorical_accuracy: 0.0917\\n\"\n",
     "     ]\n",
     "    },\n",
     "    {\n",
     "     \"data\": {\n",
     "      \"text/plain\": [\n",
     "       \"[1434.2726928710938, 0.09166667]\"\n",
     "      ]\n",
     "     },\n",
     "     \"execution_count\": 7,\n",
     "     \"metadata\": {},\n",
     "     \"output_type\": \"execute_result\"\n",
     "    }\n",
     "   ],\n",
     "   \"source\": [\n",
     "    \"test_x = np.random.random((1000, 72))\\n\",\n",
     "    \"test_y = np.random.random((1000, 10))\\n\",\n",
     "    \"model.evaluate(test_x, test_y, batch_size=32)\\n\",\n",
     "    \"test_data = tf.data.Dataset.from_tensor_slices((test_x, test_y))\\n\",\n",
     "    \"test_data = test_data.batch(32).repeat()\\n\",\n",
     "    \"model.evaluate(test_data, steps=30)\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"code\",\n",
     "   \"execution_count\": 8,\n",
     "   \"metadata\": {},\n",
     "   \"outputs\": [\n",
     "    {\n",
     "     \"name\": \"stdout\",\n",
     "     \"output_type\": \"stream\",\n",
     "     \"text\": [\n",
     "      \"[[0.03482518 0.         0.         ... 0.         0.01383898 0.00980373]\\n\",\n",
     "      \" [0.04969706 0.         0.         ... 0.         0.01390861 0.01697475]\\n\",\n",
     "      \" [0.05528085 0.         0.         ... 0.         0.01484961 0.01221495]\\n\",\n",
     "      \" ...\\n\",\n",
     "      \" [0.02390553 0.         0.         ... 0.         0.0051297  0.01121524]\\n\",\n",
     "      \" [0.04970536 0.         0.         ... 0.         0.00756324 0.01169133]\\n\",\n",
     "      \" [0.0402186  0.         0.         ... 0.         0.00886078 0.01124491]]\\n\"\n",
     "     ]\n",
     "    }\n",
     "   ],\n",
     "   \"source\": [\n",
     "    \"# predict\\n\",\n",
     "    \"result = model.predict(test_x, batch_size=32)\\n\",\n",
     "    \"print(result)\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"markdown\",\n",
     "   \"metadata\": {},\n",
     "   \"source\": [\n",
     "    \"## 4.构建高级模型\\n\",\n",
     "    \"\\n\",\n",
     "    \"### 4.1函数式api\\n\",\n",
     "    \"tf.keras.Sequential 模型是层的简单堆叠，无法表示任意模型。使用 Keras 函数式 API 可以构建复杂的模型拓扑，例如：\\n\",\n",
     "    \"\\n\",\n",
     "    \"多输入模型，\\n\",\n",
     "    \"\\n\",\n",
     "    \"多输出模型，\\n\",\n",
     "    \"\\n\",\n",
     "    \"具有共享层的模型（同一层被调用多次），\\n\",\n",
     "    \"\\n\",\n",
     "    \"具有非序列数据流的模型（例如，残差连接）。\\n\",\n",
     "    \"\\n\",\n",
     "    \"**使用函数式 API 构建的模型具有以下特征：**\\n\",\n",
     "    \"\\n\",\n",
     "    \"层实例可调用并返回张量。\\n\",\n",
     "    \"输入张量和输出张量用于定义 tf.keras.Model 实例。\\n\",\n",
     "    \"此模型的训练方式和 Sequential 模型一样。\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"code\",\n",
     "   \"execution_count\": 9,\n",
     "   \"metadata\": {},\n",
     "   \"outputs\": [\n",
     "    {\n",
     "     \"name\": \"stdout\",\n",
     "     \"output_type\": \"stream\",\n",
     "     \"text\": [\n",
     "      \"Epoch 1/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 125us/sample - loss: 12.9786 - accuracy: 0.0980\\n\",\n",
     "      \"Epoch 2/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 58us/sample - loss: 19.5004 - accuracy: 0.1060\\n\",\n",
     "      \"Epoch 3/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 44us/sample - loss: 34.5295 - accuracy: 0.1040\\n\",\n",
     "      \"Epoch 4/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 60us/sample - loss: 65.7156 - accuracy: 0.0950\\n\",\n",
     "      \"Epoch 5/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 51us/sample - loss: 118.1614 - accuracy: 0.1190\\n\"\n",
     "     ]\n",
     "    },\n",
     "    {\n",
     "     \"data\": {\n",
     "      \"text/plain\": [\n",
     "       \"<tensorflow.python.keras.callbacks.History at 0x7f998c243d68>\"\n",
     "      ]\n",
     "     },\n",
     "     \"execution_count\": 9,\n",
     "     \"metadata\": {},\n",
     "     \"output_type\": \"execute_result\"\n",
     "    }\n",
     "   ],\n",
     "   \"source\": [\n",
     "    \"input_x = tf.keras.Input(shape=(72,))\\n\",\n",
     "    \"hidden1 = layers.Dense(32, activation='relu')(input_x)\\n\",\n",
     "    \"hidden2 = layers.Dense(16, activation='relu')(hidden1)\\n\",\n",
     "    \"pred = layers.Dense(10, activation='softmax')(hidden2)\\n\",\n",
     "    \"\\n\",\n",
     "    \"model = tf.keras.Model(inputs=input_x, outputs=pred)\\n\",\n",
     "    \"model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\\n\",\n",
     "    \"             loss=tf.keras.losses.categorical_crossentropy,\\n\",\n",
     "    \"             metrics=['accuracy'])\\n\",\n",
     "    \"model.fit(train_x, train_y, batch_size=32, epochs=5)\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"markdown\",\n",
     "   \"metadata\": {},\n",
     "   \"source\": [\n",
     "    \"## 4.2模型子类化\\n\",\n",
     "    \"通过对 tf.keras.Model 进行子类化并定义您自己的前向传播来构建完全可自定义的模型。在 __init__ 方法中创建层并将它们设置为类实例的属性。在 call 方法中定义前向传播\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"code\",\n",
     "   \"execution_count\": 10,\n",
     "   \"metadata\": {},\n",
     "   \"outputs\": [\n",
     "    {\n",
     "     \"name\": \"stdout\",\n",
     "     \"output_type\": \"stream\",\n",
     "     \"text\": [\n",
     "      \"Epoch 1/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 159us/sample - loss: 14.8053 - accuracy: 0.0990\\n\",\n",
     "      \"Epoch 2/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 95us/sample - loss: 22.0737 - accuracy: 0.0960\\n\",\n",
     "      \"Epoch 3/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 62us/sample - loss: 28.5564 - accuracy: 0.0990\\n\",\n",
     "      \"Epoch 4/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 84us/sample - loss: 33.0303 - accuracy: 0.1010\\n\",\n",
     "      \"Epoch 5/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 72us/sample - loss: 36.4832 - accuracy: 0.1040\\n\"\n",
     "     ]\n",
     "    },\n",
     "    {\n",
     "     \"data\": {\n",
     "      \"text/plain\": [\n",
     "       \"<tensorflow.python.keras.callbacks.History at 0x7f995c46a198>\"\n",
     "      ]\n",
     "     },\n",
     "     \"execution_count\": 10,\n",
     "     \"metadata\": {},\n",
     "     \"output_type\": \"execute_result\"\n",
     "    }\n",
     "   ],\n",
     "   \"source\": [\n",
     "    \"class MyModel(tf.keras.Model):\\n\",\n",
     "    \"    def __init__(self, num_classes=10):\\n\",\n",
     "    \"        super(MyModel, self).__init__(name='my_model')\\n\",\n",
     "    \"        self.num_classes = num_classes\\n\",\n",
     "    \"        self.layer1 = layers.Dense(32, activation='relu')\\n\",\n",
     "    \"        self.layer2 = layers.Dense(num_classes, activation='softmax')\\n\",\n",
     "    \"    def call(self, inputs):\\n\",\n",
     "    \"        h1 = self.layer1(inputs)\\n\",\n",
     "    \"        out = self.layer2(h1)\\n\",\n",
     "    \"        return out\\n\",\n",
     "    \"    \\n\",\n",
     "    \"    def compute_output_shape(self, input_shape):\\n\",\n",
     "    \"        shape = tf.TensorShape(input_shape).as_list()\\n\",\n",
     "    \"        shape[-1] = self.num_classes\\n\",\n",
     "    \"        return tf.TensorShape(shape)\\n\",\n",
     "    \"\\n\",\n",
     "    \"model = MyModel(num_classes=10)\\n\",\n",
     "    \"model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\\n\",\n",
     "    \"             loss=tf.keras.losses.categorical_crossentropy,\\n\",\n",
     "    \"             metrics=['accuracy'])\\n\",\n",
     "    \"\\n\",\n",
     "    \"model.fit(train_x, train_y, batch_size=16, epochs=5)\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"markdown\",\n",
     "   \"metadata\": {},\n",
     "   \"source\": [\n",
     "    \"## 4.3自定义层\\n\",\n",
     "    \"通过对 tf.keras.layers.Layer 进行子类化并实现以下方法来创建自定义层：\\n\",\n",
     "    \"\\n\",\n",
     "    \"build：创建层的权重。使用 add_weight 方法添加权重。\\n\",\n",
     "    \"\\n\",\n",
     "    \"call：定义前向传播。\\n\",\n",
     "    \"\\n\",\n",
     "    \"compute_output_shape：指定在给定输入形状的情况下如何计算层的输出形状。\\n\",\n",
     "    \"或者，可以通过实现 get_config 方法和 from_config 类方法序列化层。\\n\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"code\",\n",
     "   \"execution_count\": 11,\n",
     "   \"metadata\": {},\n",
     "   \"outputs\": [\n",
     "    {\n",
     "     \"name\": \"stdout\",\n",
     "     \"output_type\": \"stream\",\n",
     "     \"text\": [\n",
     "      \"Epoch 1/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 127us/sample - loss: 11.6270 - accuracy: 0.1130\\n\",\n",
     "      \"Epoch 2/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 73us/sample - loss: 11.6259 - accuracy: 0.1130\\n\",\n",
     "      \"Epoch 3/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 72us/sample - loss: 11.6243 - accuracy: 0.1080\\n\",\n",
     "      \"Epoch 4/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 115us/sample - loss: 11.6234 - accuracy: 0.1070\\n\",\n",
     "      \"Epoch 5/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 85us/sample - loss: 11.6219 - accuracy: 0.1070\\n\"\n",
     "     ]\n",
     "    },\n",
     "    {\n",
     "     \"data\": {\n",
     "      \"text/plain\": [\n",
     "       \"<tensorflow.python.keras.callbacks.History at 0x7f994a6a07b8>\"\n",
     "      ]\n",
     "     },\n",
     "     \"execution_count\": 11,\n",
     "     \"metadata\": {},\n",
     "     \"output_type\": \"execute_result\"\n",
     "    }\n",
     "   ],\n",
     "   \"source\": [\n",
     "    \"class MyLayer(layers.Layer):\\n\",\n",
     "    \"    def __init__(self, output_dim, **kwargs):\\n\",\n",
     "    \"        self.output_dim = output_dim\\n\",\n",
     "    \"        super(MyLayer, self).__init__(**kwargs)\\n\",\n",
     "    \"    \\n\",\n",
     "    \"    def build(self, input_shape):\\n\",\n",
     "    \"        shape = tf.TensorShape((input_shape[1], self.output_dim))\\n\",\n",
     "    \"        self.kernel = self.add_weight(name='kernel1', shape=shape,\\n\",\n",
     "    \"                                   initializer='uniform', trainable=True)\\n\",\n",
     "    \"        super(MyLayer, self).build(input_shape)\\n\",\n",
     "    \"    \\n\",\n",
     "    \"    def call(self, inputs):\\n\",\n",
     "    \"        return tf.matmul(inputs, self.kernel)\\n\",\n",
     "    \"\\n\",\n",
     "    \"    def compute_output_shape(self, input_shape):\\n\",\n",
     "    \"        shape = tf.TensorShape(input_shape).as_list()\\n\",\n",
     "    \"        shape[-1] = self.output_dim\\n\",\n",
     "    \"        return tf.TensorShape(shape)\\n\",\n",
     "    \"\\n\",\n",
     "    \"    def get_config(self):\\n\",\n",
     "    \"        base_config = super(MyLayer, self).get_config()\\n\",\n",
     "    \"        base_config['output_dim'] = self.output_dim\\n\",\n",
     "    \"        return base_config\\n\",\n",
     "    \"\\n\",\n",
     "    \"    @classmethod\\n\",\n",
     "    \"    def from_config(cls, config):\\n\",\n",
     "    \"        return cls(**config)\\n\",\n",
     "    \"    \\n\",\n",
     "    \"model = tf.keras.Sequential(\\n\",\n",
     "    \"[\\n\",\n",
     "    \"    MyLayer(10),\\n\",\n",
     "    \"    layers.Activation('softmax')\\n\",\n",
     "    \"])\\n\",\n",
     "    \"\\n\",\n",
     "    \"\\n\",\n",
     "    \"model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\\n\",\n",
     "    \"             loss=tf.keras.losses.categorical_crossentropy,\\n\",\n",
     "    \"             metrics=['accuracy'])\\n\",\n",
     "    \"\\n\",\n",
     "    \"model.fit(train_x, train_y, batch_size=16, epochs=5)\\n\",\n",
     "    \"\\n\",\n",
     "    \"        \"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"markdown\",\n",
     "   \"metadata\": {},\n",
     "   \"source\": [\n",
     "    \"## 4.3回调\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"code\",\n",
     "   \"execution_count\": 12,\n",
     "   \"metadata\": {},\n",
     "   \"outputs\": [\n",
     "    {\n",
     "     \"name\": \"stdout\",\n",
     "     \"output_type\": \"stream\",\n",
     "     \"text\": [\n",
     "      \"Train on 1000 samples, validate on 200 samples\\n\",\n",
     "      \"Epoch 1/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 214us/sample - loss: 11.6202 - accuracy: 0.1050 - val_loss: 11.5276 - val_accuracy: 0.0950\\n\",\n",
     "      \"Epoch 2/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 106us/sample - loss: 11.6219 - accuracy: 0.1080 - val_loss: 11.5256 - val_accuracy: 0.1050\\n\",\n",
     "      \"Epoch 3/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 77us/sample - loss: 11.6234 - accuracy: 0.1020 - val_loss: 11.5226 - val_accuracy: 0.1100\\n\",\n",
     "      \"Epoch 4/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 94us/sample - loss: 11.6213 - accuracy: 0.0980 - val_loss: 11.5266 - val_accuracy: 0.1050\\n\",\n",
     "      \"Epoch 5/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 88us/sample - loss: 11.6211 - accuracy: 0.1010 - val_loss: 11.5253 - val_accuracy: 0.1150\\n\"\n",
     "     ]\n",
     "    },\n",
     "    {\n",
     "     \"data\": {\n",
     "      \"text/plain\": [\n",
     "       \"<tensorflow.python.keras.callbacks.History at 0x7f995c4b7e80>\"\n",
     "      ]\n",
     "     },\n",
     "     \"execution_count\": 12,\n",
     "     \"metadata\": {},\n",
     "     \"output_type\": \"execute_result\"\n",
     "    }\n",
     "   ],\n",
     "   \"source\": [\n",
     "    \"callbacks = [\\n\",\n",
     "    \"    tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\\n\",\n",
     "    \"    tf.keras.callbacks.TensorBoard(log_dir='./logs')\\n\",\n",
     "    \"]\\n\",\n",
     "    \"model.fit(train_x, train_y, batch_size=16, epochs=5,\\n\",\n",
     "    \"         callbacks=callbacks, validation_data=(val_x, val_y))\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"markdown\",\n",
     "   \"metadata\": {},\n",
     "   \"source\": [\n",
     "    \"## 5保持和恢复\\n\",\n",
     "    \"### 5.1权重保存\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"code\",\n",
     "   \"execution_count\": 13,\n",
     "   \"metadata\": {},\n",
     "   \"outputs\": [],\n",
     "   \"source\": [\n",
     "    \"model = tf.keras.Sequential([\\n\",\n",
     "    \"layers.Dense(64, activation='relu'),\\n\",\n",
     "    \"layers.Dense(10, activation='softmax')])\\n\",\n",
     "    \"\\n\",\n",
     "    \"model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\\n\",\n",
     "    \"              loss='categorical_crossentropy',\\n\",\n",
     "    \"              metrics=['accuracy'])\\n\",\n",
     "    \"\\n\",\n",
     "    \"model.save_weights('./weights/model')\\n\",\n",
     "    \"model.load_weights('./weights/model')\\n\",\n",
     "    \"model.save_weights('./model.h5')\\n\",\n",
     "    \"model.load_weights('./model.h5')\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"markdown\",\n",
     "   \"metadata\": {},\n",
     "   \"source\": [\n",
     "    \"### 5.2保存网络结构\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"code\",\n",
     "   \"execution_count\": 14,\n",
     "   \"metadata\": {},\n",
     "   \"outputs\": [\n",
     "    {\n",
     "     \"name\": \"stdout\",\n",
     "     \"output_type\": \"stream\",\n",
     "     \"text\": [\n",
     "      \"{'backend': 'tensorflow',\\n\",\n",
     "      \" 'class_name': 'Sequential',\\n\",\n",
     "      \" 'config': {'layers': [{'class_name': 'Dense',\\n\",\n",
     "      \"                        'config': {'activation': 'relu',\\n\",\n",
     "      \"                                   'activity_regularizer': None,\\n\",\n",
     "      \"                                   'bias_constraint': None,\\n\",\n",
     "      \"                                   'bias_initializer': {'class_name': 'Zeros',\\n\",\n",
     "      \"                                                        'config': {}},\\n\",\n",
     "      \"                                   'bias_regularizer': None,\\n\",\n",
     "      \"                                   'dtype': None,\\n\",\n",
     "      \"                                   'kernel_constraint': None,\\n\",\n",
     "      \"                                   'kernel_initializer': {'class_name': 'GlorotUniform',\\n\",\n",
     "      \"                                                          'config': {'seed': None}},\\n\",\n",
     "      \"                                   'kernel_regularizer': None,\\n\",\n",
     "      \"                                   'name': 'dense_17',\\n\",\n",
     "      \"                                   'trainable': True,\\n\",\n",
     "      \"                                   'units': 64,\\n\",\n",
     "      \"                                   'use_bias': True}},\\n\",\n",
     "      \"                       {'class_name': 'Dense',\\n\",\n",
     "      \"                        'config': {'activation': 'softmax',\\n\",\n",
     "      \"                                   'activity_regularizer': None,\\n\",\n",
     "      \"                                   'bias_constraint': None,\\n\",\n",
     "      \"                                   'bias_initializer': {'class_name': 'Zeros',\\n\",\n",
     "      \"                                                        'config': {}},\\n\",\n",
     "      \"                                   'bias_regularizer': None,\\n\",\n",
     "      \"                                   'dtype': None,\\n\",\n",
     "      \"                                   'kernel_constraint': None,\\n\",\n",
     "      \"                                   'kernel_initializer': {'class_name': 'GlorotUniform',\\n\",\n",
     "      \"                                                          'config': {'seed': None}},\\n\",\n",
     "      \"                                   'kernel_regularizer': None,\\n\",\n",
     "      \"                                   'name': 'dense_18',\\n\",\n",
     "      \"                                   'trainable': True,\\n\",\n",
     "      \"                                   'units': 10,\\n\",\n",
     "      \"                                   'use_bias': True}}],\\n\",\n",
     "      \"            'name': 'sequential_3'},\\n\",\n",
     "      \" 'keras_version': '2.2.4-tf'}\\n\"\n",
     "     ]\n",
     "    }\n",
     "   ],\n",
     "   \"source\": [\n",
     "    \"# 序列化成json\\n\",\n",
     "    \"import json\\n\",\n",
     "    \"import pprint\\n\",\n",
     "    \"json_str = model.to_json()\\n\",\n",
     "    \"pprint.pprint(json.loads(json_str))\\n\",\n",
     "    \"fresh_model = tf.keras.models.model_from_json(json_str)\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"code\",\n",
     "   \"execution_count\": 15,\n",
     "   \"metadata\": {},\n",
     "   \"outputs\": [\n",
     "    {\n",
     "     \"name\": \"stdout\",\n",
     "     \"output_type\": \"stream\",\n",
     "     \"text\": [\n",
     "      \"backend: tensorflow\\n\",\n",
     "      \"class_name: Sequential\\n\",\n",
     "      \"config:\\n\",\n",
     "      \"  layers:\\n\",\n",
     "      \"  - class_name: Dense\\n\",\n",
     "      \"    config:\\n\",\n",
     "      \"      activation: relu\\n\",\n",
     "      \"      activity_regularizer: null\\n\",\n",
     "      \"      bias_constraint: null\\n\",\n",
     "      \"      bias_initializer:\\n\",\n",
     "      \"        class_name: Zeros\\n\",\n",
     "      \"        config: {}\\n\",\n",
     "      \"      bias_regularizer: null\\n\",\n",
     "      \"      dtype: null\\n\",\n",
     "      \"      kernel_constraint: null\\n\",\n",
     "      \"      kernel_initializer:\\n\",\n",
     "      \"        class_name: GlorotUniform\\n\",\n",
     "      \"        config: {seed: null}\\n\",\n",
     "      \"      kernel_regularizer: null\\n\",\n",
     "      \"      name: dense_17\\n\",\n",
     "      \"      trainable: true\\n\",\n",
     "      \"      units: 64\\n\",\n",
     "      \"      use_bias: true\\n\",\n",
     "      \"  - class_name: Dense\\n\",\n",
     "      \"    config:\\n\",\n",
     "      \"      activation: softmax\\n\",\n",
     "      \"      activity_regularizer: null\\n\",\n",
     "      \"      bias_constraint: null\\n\",\n",
     "      \"      bias_initializer:\\n\",\n",
     "      \"        class_name: Zeros\\n\",\n",
     "      \"        config: {}\\n\",\n",
     "      \"      bias_regularizer: null\\n\",\n",
     "      \"      dtype: null\\n\",\n",
     "      \"      kernel_constraint: null\\n\",\n",
     "      \"      kernel_initializer:\\n\",\n",
     "      \"        class_name: GlorotUniform\\n\",\n",
     "      \"        config: {seed: null}\\n\",\n",
     "      \"      kernel_regularizer: null\\n\",\n",
     "      \"      name: dense_18\\n\",\n",
     "      \"      trainable: true\\n\",\n",
     "      \"      units: 10\\n\",\n",
     "      \"      use_bias: true\\n\",\n",
     "      \"  name: sequential_3\\n\",\n",
     "      \"keras_version: 2.2.4-tf\\n\",\n",
     "      \"\\n\"\n",
     "     ]\n",
     "    }\n",
     "   ],\n",
     "   \"source\": [\n",
     "    \"# 保持为yaml格式  #需要提前安装pyyaml\\n\",\n",
     "    \"\\n\",\n",
     "    \"yaml_str = model.to_yaml()\\n\",\n",
     "    \"print(yaml_str)\\n\",\n",
     "    \"fresh_model = tf.keras.models.model_from_yaml(yaml_str)\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"markdown\",\n",
     "   \"metadata\": {},\n",
     "   \"source\": [\n",
     "    \"### 5.3保存整个模型\\n\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"code\",\n",
     "   \"execution_count\": 16,\n",
     "   \"metadata\": {},\n",
     "   \"outputs\": [\n",
     "    {\n",
     "     \"name\": \"stdout\",\n",
     "     \"output_type\": \"stream\",\n",
     "     \"text\": [\n",
     "      \"Epoch 1/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 131us/sample - loss: 11.6308 - accuracy: 0.1040\\n\",\n",
     "      \"Epoch 2/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 40us/sample - loss: 11.6897 - accuracy: 0.1080\\n\",\n",
     "      \"Epoch 3/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 55us/sample - loss: 11.7418 - accuracy: 0.1070\\n\",\n",
     "      \"Epoch 4/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 43us/sample - loss: 11.7983 - accuracy: 0.1060\\n\",\n",
     "      \"Epoch 5/5\\n\",\n",
     "      \"1000/1000 [==============================] - 0s 47us/sample - loss: 11.8449 - accuracy: 0.0910\\n\"\n",
     "     ]\n",
     "    }\n",
     "   ],\n",
     "   \"source\": [\n",
     "    \"model = tf.keras.Sequential([\\n\",\n",
     "    \"  layers.Dense(10, activation='softmax', input_shape=(72,)),\\n\",\n",
     "    \"  layers.Dense(10, activation='softmax')\\n\",\n",
     "    \"])\\n\",\n",
     "    \"model.compile(optimizer='rmsprop',\\n\",\n",
     "    \"              loss='categorical_crossentropy',\\n\",\n",
     "    \"              metrics=['accuracy'])\\n\",\n",
     "    \"model.fit(train_x, train_y, batch_size=32, epochs=5)\\n\",\n",
     "    \"model.save('all_model.h5')\\n\",\n",
     "    \"model = tf.keras.models.load_model('all_model.h5')\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"markdown\",\n",
     "   \"metadata\": {},\n",
     "   \"source\": [\n",
     "    \"## 6.将keras用于Estimator\\n\",\n",
     "    \"Estimator API 用于针对分布式环境训练模型。它适用于一些行业使用场景，例如用大型数据集进行分布式训练并导出模型以用于生产\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"code\",\n",
     "   \"execution_count\": 17,\n",
     "   \"metadata\": {},\n",
     "   \"outputs\": [\n",
     "    {\n",
     "     \"name\": \"stderr\",\n",
     "     \"output_type\": \"stream\",\n",
     "     \"text\": [\n",
     "      \"W0308 22:45:28.520160 140299441469184 estimator.py:1799] Using temporary folder as model directory: /tmp/tmpzg_jzz1o\\n\"\n",
     "     ]\n",
     "    }\n",
     "   ],\n",
     "   \"source\": [\n",
     "    \"model = tf.keras.Sequential([layers.Dense(10,activation='softmax'),\\n\",\n",
     "    \"                          layers.Dense(10,activation='softmax')])\\n\",\n",
     "    \"\\n\",\n",
     "    \"model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\\n\",\n",
     "    \"              loss='categorical_crossentropy',\\n\",\n",
     "    \"              metrics=['accuracy'])\\n\",\n",
     "    \"\\n\",\n",
     "    \"estimator = tf.keras.estimator.model_to_estimator(model)\"\n",
     "   ]\n",
     "  },\n",
     "  {\n",
     "   \"cell_type\": \"code\",\n",
     "   \"execution_count\": null,\n",
     "   \"metadata\": {},\n",
     "   \"outputs\": [],\n",
     "   \"source\": []\n",
     "  }\n",
     " ],\n",
     " \"metadata\": {\n",
     "  \"kernelspec\": {\n",
     "   \"display_name\": \"Python 3\",\n",
     "   \"language\": \"python\",\n",
     "   \"name\": \"python3\"\n",
     "  },\n",
     "  \"language_info\": {\n",
     "   \"codemirror_mode\": {\n",
     "    \"name\": \"ipython\",\n",
     "    \"version\": 3\n",
     "   },\n",
     "   \"file_extension\": \".py\",\n",
     "   \"mimetype\": \"text/x-python\",\n",
     "   \"name\": \"python\",\n",
     "   \"nbconvert_exporter\": \"python\",\n",
     "   \"pygments_lexer\": \"ipython3\",\n",
     "   \"version\": \"3.6.6\"\n",
     "  }\n",
     " },\n",
     " \"nbformat\": 4,\n",
     " \"nbformat_minor\": 2\n",
     "}\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}